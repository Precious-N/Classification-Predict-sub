{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8834300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Precious\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Precious\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import IFrame\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import imblearn\n",
    "import csv\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import string\n",
    "import urllib\n",
    "import math\n",
    "import re\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7e2bb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d1b59dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d7c147a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "aa7d9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www.\\.\\S+') \n",
    "    return url_pattern.sub(r'',text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c7f1fb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = train['message'][2]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f3f77dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late  '"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9f0a0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "    \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4a5ad093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @rawstory: researchers say we have three years to act on climate change before it’s too late https://t.co/wdt0kdur2f https://t.co/z0anpt…'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_lower(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "27cffb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "def get_roots(text):\n",
    "    \" \".join([stemmer.stem(w) for w in str(text).split()])\n",
    "    return\" \".join([stemmer.stem(w) for w in str(text).split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "aac1d787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @rawstory: research say we have three year to act on climat chang befor it too late https://t.co/wdt0kdur2f https://t.co/z0anpt…'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_roots(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "dd203efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "7f9cc26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@',\n",
       " 'RawStory',\n",
       " ':',\n",
       " 'Researchers',\n",
       " 'say',\n",
       " 'we',\n",
       " 'have',\n",
       " 'three',\n",
       " 'years',\n",
       " 'to',\n",
       " 'act',\n",
       " 'on',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'before',\n",
       " 'it’s',\n",
       " 'too',\n",
       " 'late',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/WdT0KdUr2f',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/Z0ANPT…']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e277ab10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late  '"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet1 = remove_urls(tweet)\n",
    "tweet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "bcc5e3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @rawstory: researchers say we have three years to act on climate change before it’s too late https://t.co/wdt0kdur2f https://t.co/z0anpt…'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet2 = to_lower(tweet)\n",
    "tweet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "21f28ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @rawstory: research say we have three year to act on climat chang befor it too late https://t.co/wdt0kdur2f https://t.co/z0anpt…'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet3 = get_roots(tweet)\n",
    "tweet3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a243055b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@',\n",
       " 'RawStory',\n",
       " ':',\n",
       " 'Researchers',\n",
       " 'say',\n",
       " 'we',\n",
       " 'have',\n",
       " 'three',\n",
       " 'years',\n",
       " 'to',\n",
       " 'act',\n",
       " 'on',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'before',\n",
       " 'it’s',\n",
       " 'too',\n",
       " 'late',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/WdT0KdUr2f',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/Z0ANPT…']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet4 = tokenizer.tokenize(tweet)\n",
    "tweet4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e8c64326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    PolySciMajor EPA chief doesn't think carbon di...\n",
       "1    It's not like we lack evidence of anthropogeni...\n",
       "2    RT @RawStory: Researchers say we have three ye...\n",
       "3    #TodayinMaker# WIRED : 2016 was a pivotal year...\n",
       "4    RT @SoyNovioDeTodas: It's 2016, and a racist, ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['message'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "003207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['message_clean'] = train['message'].apply(remove_urls).apply(to_lower).apply(get_roots).apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a2611a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [polyscimajor, epa, chief, does, n't, think, c...\n",
       "1    [it, not, like, we, lack, evid, of, anthropoge...\n",
       "2    [rt, @, rawstory, :, research, say, we, have, ...\n",
       "3    [#, todayinmaker, #, wire, :, 2016, was, a, pi...\n",
       "4    [rt, @, soynoviodetodas, :, it, 2016, ,, and, ...\n",
       "Name: message_clean, dtype: object"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['message_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "5d77605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Precious\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tt = TfidfVectorizer(preprocessor = list,tokenizer =list,ngram_range=(1,2),min_df = 2,strip_accents = 'ascii',smooth_idf = False)\n",
    "\n",
    "tt.fit(train['message_clean'])\n",
    "vect = tt.transform(train['message_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a109d33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 35761)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec =tt.transform(train['message_clean'])\n",
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d8064eb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.21 GiB for an array with shape (15819, 35761) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8524/588375139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.21 GiB for an array with shape (15819, 35761) and data type float64"
     ]
    }
   ],
   "source": [
    "train_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec772c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2b474c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    1\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['sentiment'].apply(str)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "7a463a65",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.21 GiB for an array with shape (15819, 35761) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8524/272454594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.21 GiB for an array with shape (15819, 35761) and data type float64"
     ]
    }
   ],
   "source": [
    "x = train_vec.toarray()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "7e83af88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "965b94cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10546, 15819]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8524/3518356244.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstratify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \"\"\"\n\u001b[0;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10546, 15819]"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,stratify = y,random_state= 42)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "74b826a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver= \"liblinear\",random_state = 42)\n",
    "model_lr = lr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d31f1c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '1', '1', ..., '0', '1', '1'], dtype=object)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = lr.predict(X_test)\n",
    "target_names = ['-1','0','1','2']\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "dc185700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         -1       0.84      0.20      1.00      0.32      0.45      0.18       259\n",
      "          0       0.70      0.28      0.98      0.40      0.52      0.26       471\n",
      "          1       0.70      0.93      0.54      0.80      0.71      0.52      1706\n",
      "          2       0.82      0.73      0.95      0.77      0.84      0.68       728\n",
      "\n",
      "avg / total       0.74      0.73      0.74      0.70      0.69      0.49      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report_imbalanced(y_test,y_pred_test,target_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "95813168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285082174462706"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred_test,average ='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "45078642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5746349385850005"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred_test,average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b0958406",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "608fbe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "805d3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['URL'] = test['message'].str.extractall('(https?://[^>]+)').unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0dc78a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www.\\.\\S+')\n",
    "    return url_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "dc18e60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The scary, unimpeachable evidence that climate change is already here: https://t.co/yAedqcV9Ki #itstimetochange #climatechange @ZEROCO2_;..'"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = test['message'][2]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c374f7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The scary, unimpeachable evidence that climate change is already here:  #itstimetochange #climatechange @ZEROCO2_;..'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9d47e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "     \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "c21a9031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the scary, unimpeachable evidence that climate change is already here: https://t.co/yaedqcv9ki #itstimetochange #climatechange @zeroco2_;..'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_lower(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "00a350f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "def get_roots(text):\n",
    "    \" \".join([stemmer.stem(w) for w in str(text).split()])\n",
    "    return\" \".join([stemmer.stem(w) for w in str(text).split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c4745759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the scary, unimpeach evid that climat chang is alreadi here: https://t.co/yaedqcv9ki #itstimetochang #climatechang @zeroco2_;..'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_roots(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "af357268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "e5b23735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'scary',\n",
       " ',',\n",
       " 'unimpeachable',\n",
       " 'evidence',\n",
       " 'that',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'is',\n",
       " 'already',\n",
       " 'here',\n",
       " ':',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/yAedqcV9Ki',\n",
       " '#',\n",
       " 'itstimetochange',\n",
       " '#',\n",
       " 'climatechange',\n",
       " '@',\n",
       " 'ZEROCO2_',\n",
       " ';',\n",
       " '..']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "99d99171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The scary, unimpeachable evidence that climate change is already here:  #itstimetochange #climatechange @ZEROCO2_;..'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet1 = remove_urls(tweet)\n",
    "tweet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "cd3f4f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the scary, unimpeachable evidence that climate change is already here: https://t.co/yaedqcv9ki #itstimetochange #climatechange @zeroco2_;..'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet2 = to_lower(tweet)\n",
    "tweet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "c6bc3f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the scary, unimpeach evid that climat chang is alreadi here: https://t.co/yaedqcv9ki #itstimetochang #climatechang @zeroco2_;..'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet3 = get_roots(tweet)\n",
    "tweet3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "555a77a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'scary',\n",
       " ',',\n",
       " 'unimpeachable',\n",
       " 'evidence',\n",
       " 'that',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'is',\n",
       " 'already',\n",
       " 'here',\n",
       " ':',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/yAedqcV9Ki',\n",
       " '#',\n",
       " 'itstimetochange',\n",
       " '#',\n",
       " 'climatechange',\n",
       " '@',\n",
       " 'ZEROCO2_',\n",
       " ';',\n",
       " '..']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet4 = tokenizer.tokenize(tweet)\n",
    "tweet4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "7220f03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [europ, will, now, be, look, to, china, to, ma...\n",
       "1    [combin, this, with, the, poll, of, staffer, r...\n",
       "2    [the, scary, ,, unimpeach, evid, that, climat,...\n",
       "3    [@, karoli, @, morgfair, @, osborneink, @, dai...\n",
       "4    [rt, @, fakewillmoore, :, femal, orgasm, caus,...\n",
       "Name: message_clean, dtype: object"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['message_clean']= test['message'].apply(remove_urls).apply(to_lower).apply(get_roots).apply(tokenizer.tokenize)\n",
    "test['message_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "831778cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tt = TfidfVectorizer(preprocessor = list,tokenizer =list,ngram_range=(1,2),min_df = 2,strip_accents = 'ascii',smooth_idf = False)\n",
    "\n",
    "#tt.fit(test['message_clean'])\n",
    "#vect = tt.transform(train['message_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "dfa3a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 35761)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec =tt.transform(test['message_clean'])\n",
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9f8d87fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.81 GiB for an array with shape (10546, 35761) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8524/832144698.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.81 GiB for an array with shape (10546, 35761) and data type float64"
     ]
    }
   ],
   "source": [
    "test_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2862fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_vec.toarray()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "75945087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         -1       0.20      0.84      0.93      0.32      0.88      0.78        62\n",
      "          0       0.28      0.70      0.89      0.40      0.79      0.61       188\n",
      "          1       0.93      0.70      0.87      0.80      0.78      0.60      2265\n",
      "          2       0.73      0.82      0.92      0.77      0.87      0.75       649\n",
      "\n",
      "avg / total       0.84      0.73      0.88      0.76      0.80      0.63      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report_imbalanced(y_pred_test,y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1997bdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5746349385850005"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred_test,average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c5ce574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lr.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8025d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame (test['tweetid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "82b18000",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['sentiment'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d70757ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('nafeesa.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
